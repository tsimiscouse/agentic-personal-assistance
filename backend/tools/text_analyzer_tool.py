"""
Text Analyzer Tool
General-purpose text summarization and analysis with PDF support
Designed for study materials, reports, articles, and any text content
"""

from langchain.tools import tool
from langchain_groq import ChatGroq
from loguru import logger
from config.settings import get_settings
import PyPDF2
import io
from typing import Optional

settings = get_settings()

# Token usage optimization
MAX_TEXT_LENGTH = 8000  # Limit input to ~2000 tokens (4 chars ‚âà 1 token)
SUMMARY_TEMPERATURE = 0.2  # Low temperature for consistency
STUDY_TEMPERATURE = 0.4  # Slightly higher for creative explanations


# ============================================
# MAIN SUMMARIZATION TOOL
# ============================================

@tool
def summarize_text_tool(text_input: str, is_pdf_path: bool = False) -> str:
    """
    Summarize any text content into clear, structured bullet points.

    IMPORTANT: Pass the FULL TEXT CONTENT directly to this tool, not just filenames or references.
    When document content is provided in the message, use that complete text as input.

    Perfect for:
    - Study materials (textbooks, lecture notes, research papers)
    - Reports (business, technical, academic)
    - Articles and blog posts
    - Documentation and guides
    - Meeting notes and transcripts
    - Documents uploaded by users (PDF, DOCX, PPTX, etc.)

    Input examples:
    - Plain text: "Quantum computing is a revolutionary approach... [full content]"
    - Document content: "[Complete extracted text from user's uploaded document]"
    - Long articles: "[Full article text here]"

    Args:
        text_input: The FULL TEXT CONTENT to summarize (not a file path or reference)
        is_pdf_path: Set to True ONLY if input is an actual file path (rarely used)

    Returns:
        str: Structured summary with main topics and key points
    """
    try:
        # Extract text from PDF if needed
        if is_pdf_path:
            logger.info(f"Extracting text from PDF: {text_input}")
            text_content = _extract_text_from_pdf(text_input)

            if not text_content:
                return "I couldn't extract text from the PDF file. Please ensure it's a valid text-based PDF."
        else:
            text_content = text_input

        # Truncate if too long for token efficiency
        if len(text_content) > MAX_TEXT_LENGTH:
            logger.info(f"Truncating text from {len(text_content)} to {MAX_TEXT_LENGTH} chars")
            text_content = text_content[:MAX_TEXT_LENGTH] + "\n\n[Note: Text was truncated for processing]"

        logger.info(f"Summarizing text ({len(text_content)} characters)")

        # Initialize LLM with token-efficient settings
        llm = ChatGroq(
            api_key=settings.groq_api_key,
            model_name=settings.groq_model,  # llama-3.1-8b-instant for speed
            temperature=SUMMARY_TEMPERATURE,
            max_tokens=500  # Limit output for efficiency
        )

        # Create efficient summarization prompt
        prompt = f"""Analyze and summarize the following text in a clear, structured format.

Text to summarize:
{text_content}

Provide a summary with this structure:

üìã **Main Topic:**
[One sentence describing the overall subject]

üéØ **Key Points:**
‚Ä¢ [Main point 1]
‚Ä¢ [Main point 2]
‚Ä¢ [Main point 3]
‚Ä¢ [Continue with important points - max 6 points]

üí° **Key Takeaways:**
‚Ä¢ [Important insight 1]
‚Ä¢ [Important insight 2]

Keep it concise and focused on the most important information. Use bullet points for clarity."""

        # Get summary from LLM
        response = llm.invoke(prompt)

        # Extract content
        if hasattr(response, 'content'):
            summary = response.content
        else:
            summary = str(response)

        logger.info("Summary generated successfully")

        return summary.strip()

    except Exception as e:
        logger.error(f"Error in summarize_text_tool: {e}")
        return "I encountered an error while summarizing the text. Please ensure the content is valid or try with shorter text."


# ============================================
# KEY POINTS EXTRACTION TOOL
# ============================================

@tool
def extract_key_points_tool(text_input: str, is_pdf_path: bool = False) -> str:
    """
    Extract main topics and key points from any text content.

    Great for:
    - Quick overview of study materials
    - Identifying important concepts
    - Creating study guides
    - Reviewing long documents

    Args:
        text_input: Text content or PDF file path
        is_pdf_path: Set to True if input is a PDF file path

    Returns:
        str: Organized list of main topics and key points
    """
    try:
        # Extract text from PDF if needed
        if is_pdf_path:
            text_content = _extract_text_from_pdf(text_input)
            if not text_content:
                return "Couldn't extract text from PDF."
        else:
            text_content = text_input

        # Truncate for efficiency
        if len(text_content) > MAX_TEXT_LENGTH:
            text_content = text_content[:MAX_TEXT_LENGTH]

        logger.info("Extracting key points")

        llm = ChatGroq(
            api_key=settings.groq_api_key,
            model_name=settings.groq_model,
            temperature=SUMMARY_TEMPERATURE,
            max_tokens=400
        )

        prompt = f"""Extract and organize the main topics and key points from this text.

Text:
{text_content}

Format your response as:

**Main Topics:**
1. [Topic 1]
2. [Topic 2]
3. [Topic 3]
[Continue if needed, max 5 topics]

**Key Points:**
‚Ä¢ [Important point 1]
‚Ä¢ [Important point 2]
‚Ä¢ [Important point 3]
‚Ä¢ [Important point 4]
‚Ä¢ [Important point 5]
[Continue if needed, max 8 points]

Focus on the most important and actionable information."""

        response = llm.invoke(prompt)
        key_points = response.content if hasattr(response, 'content') else str(response)

        logger.info("Key points extracted successfully")

        return key_points.strip()

    except Exception as e:
        logger.error(f"Error extracting key points: {e}")
        return "Error extracting key points from the text."


# ============================================
# STUDY PARTNER - CONCEPT EXPLANATION TOOL
# ============================================

@tool
def explain_concept_tool(concept_query: str, context_text: Optional[str] = None) -> str:
    """
    Explain concepts in simple terms - your AI study partner.

    Use for:
    - Understanding difficult concepts
    - Breaking down complex topics
    - Getting examples and analogies
    - Study session Q&A

    Args:
        concept_query: The concept or question to explain (e.g., "What is photosynthesis?")
        context_text: Optional context from study materials

    Returns:
        str: Clear, friendly explanation with examples
    """
    try:
        logger.info(f"Explaining concept: {concept_query[:100]}")

        llm = ChatGroq(
            api_key=settings.groq_api_key,
            model_name=settings.groq_model,
            temperature=STUDY_TEMPERATURE,  # Slightly higher for better explanations
            max_tokens=600
        )

        # Build context-aware prompt
        context_section = ""
        if context_text:
            # Truncate context if too long
            if len(context_text) > 3000:
                context_text = context_text[:3000]
            context_section = f"\n\nContext from study materials:\n{context_text}\n"

        prompt = f"""You are a friendly and knowledgeable study partner. Explain the following concept in a clear, easy-to-understand way.
{context_section}
Concept to explain: {concept_query}

Provide your explanation in this format:

üéì **Simple Explanation:**
[Explain in simple terms, like explaining to a friend]

üìù **Key Points to Remember:**
‚Ä¢ [Important point 1]
‚Ä¢ [Important point 2]
‚Ä¢ [Important point 3]

üí° **Example:**
[Provide a practical example or analogy if helpful]

Keep it conversational, clear, and helpful for studying."""

        response = llm.invoke(prompt)
        explanation = response.content if hasattr(response, 'content') else str(response)

        logger.info("Concept explained successfully")

        return explanation.strip()

    except Exception as e:
        logger.error(f"Error explaining concept: {e}")
        return "I had trouble explaining that concept. Could you rephrase your question?"


# ============================================
# DOCUMENT Q&A TOOL (for specific questions)
# ============================================

@tool
def answer_document_question_tool(input_text: str) -> str:
    """
    Answer specific questions about a document.

    Use this when user asks questions about a document they uploaded.
    The input should contain BOTH the question AND the document content.

    CRITICAL: You MUST extract the document content from between the markers:
    ---START OF DOCUMENT---
    [document text]
    ---END OF DOCUMENT---

    Then extract the question from the user's request.

    Perfect for:
    - "What is [specific concept] in the document?"
    - "Explain [term] from the document"
    - "What does the document say about [topic]?"
    - Questions after document upload

    Args:
        input_text: Combined text containing both question and document content with markers

    Returns:
        str: Direct answer to the question based on document content
    """
    try:
        import re

        # Extract document content between markers
        doc_match = re.search(r'---START OF DOCUMENT---\s*(.*?)\s*---END OF DOCUMENT---', input_text, re.DOTALL)

        if not doc_match:
            return "‚ùå Error: Document content not found. Please ensure the document is properly formatted with START/END markers."

        document_content = doc_match.group(1).strip()

        # Extract the question - look for common patterns
        question = None

        # Try to find explicit question markers
        question_patterns = [
            r'USER REQUEST:\s*(.+?)(?:\n|$)',
            r'QUESTION:\s*(.+?)(?:\n|$)',
            r'question:\s*["\'](.+?)["\']',
            r'Question:\s*(.+?)(?:\n|$)'
        ]

        for pattern in question_patterns:
            q_match = re.search(pattern, input_text, re.IGNORECASE)
            if q_match:
                question = q_match.group(1).strip()
                break

        # If no explicit marker, try to extract from instruction text
        if not question:
            # Look for instruction to use the tool with a question
            inst_match = re.search(r'with the question:\s*["\'](.+?)["\']', input_text, re.IGNORECASE)
            if inst_match:
                question = inst_match.group(1).strip()

        # Last resort: extract text before the document markers
        if not question:
            before_doc = input_text.split('---START OF DOCUMENT---')[0].strip()
            # Remove instruction text
            before_doc = re.sub(r'\*\*INSTRUCTION:\*\*.*', '', before_doc, flags=re.DOTALL).strip()
            before_doc = re.sub(r'\*\*DOCUMENT CONTEXT.*', '', before_doc, flags=re.DOTALL).strip()
            if before_doc and len(before_doc) < 200:  # Reasonable question length
                question = before_doc
            else:
                question = "What is this document about?"  # Default question

        logger.info(f"Answering question about document: {question[:100]}")
        logger.info(f"Document content length: {len(document_content)} chars")

        # Truncate document if too long
        if len(document_content) > MAX_TEXT_LENGTH:
            logger.info(f"Truncating document from {len(document_content)} to {MAX_TEXT_LENGTH} chars")
            document_content = document_content[:MAX_TEXT_LENGTH]

        llm = ChatGroq(
            api_key=settings.groq_api_key,
            model_name=settings.groq_model,
            temperature=0.3,
            max_tokens=600
        )

        prompt = f"""You are helping a user understand their document. Answer their specific question based ONLY on the document content provided.

DOCUMENT CONTENT:
{document_content}

USER QUESTION: {question}

Provide a clear, direct answer in this format:

üìñ **Answer:**
[Direct answer to the question based on the document]

üìù **Details:**
‚Ä¢ [Relevant detail 1 from document]
‚Ä¢ [Relevant detail 2 from document]
‚Ä¢ [Relevant detail 3 from document]

üí° **Context:**
[Brief additional context from the document if helpful]

IMPORTANT:
- Answer ONLY based on what's in the document
- If the information isn't in the document, say so clearly
- Quote or reference specific parts when helpful
- Keep the answer focused and relevant"""

        response = llm.invoke(prompt)
        answer = response.content if hasattr(response, 'content') else str(response)

        logger.info("Document question answered successfully")

        return answer.strip()

    except Exception as e:
        logger.error(f"Error answering document question: {e}", exc_info=True)
        return "I had trouble finding that information in the document. Could you rephrase your question?"


# ============================================
# COMPARISON TOOL (for study materials)
# ============================================

@tool
def compare_concepts_tool(concept1: str, concept2: str, context_text: Optional[str] = None) -> str:
    """
    Compare two concepts or topics - great for understanding differences.

    Use for:
    - Understanding differences between similar concepts
    - Comparing theories or approaches
    - Distinguishing between related terms
    - Study review and exam prep

    Args:
        concept1: First concept to compare
        concept2: Second concept to compare
        context_text: Optional context from study materials

    Returns:
        str: Clear comparison showing similarities and differences
    """
    try:
        logger.info(f"Comparing: {concept1} vs {concept2}")

        llm = ChatGroq(
            api_key=settings.groq_api_key,
            model_name=settings.groq_model,
            temperature=SUMMARY_TEMPERATURE,
            max_tokens=500
        )

        context_section = ""
        if context_text:
            if len(context_text) > 2000:
                context_text = context_text[:2000]
            context_section = f"\n\nContext:\n{context_text}\n"

        prompt = f"""Compare and contrast these two concepts:{context_section}

Concept A: {concept1}
Concept B: {concept2}

Format:

üîπ **{concept1}:**
[Brief description]

üîπ **{concept2}:**
[Brief description]

**Key Differences:**
‚Ä¢ [Difference 1]
‚Ä¢ [Difference 2]
‚Ä¢ [Difference 3]

**Similarities:**
‚Ä¢ [Similarity 1]
‚Ä¢ [Similarity 2]

**When to use each:**
‚Ä¢ Use {concept1} when: [scenario]
‚Ä¢ Use {concept2} when: [scenario]

Keep it clear and focused on helping understand the differences."""

        response = llm.invoke(prompt)
        comparison = response.content if hasattr(response, 'content') else str(response)

        logger.info("Comparison completed successfully")

        return comparison.strip()

    except Exception as e:
        logger.error(f"Error comparing concepts: {e}")
        return "I had trouble comparing those concepts. Please try again."


# ============================================
# PDF PROCESSING FUNCTIONS
# ============================================

def _extract_text_from_pdf(pdf_path: str) -> str:
    """
    Extract text from PDF file.

    Args:
        pdf_path: Path to PDF file

    Returns:
        str: Extracted text
    """
    try:
        extracted_text = []

        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)

            # Get number of pages
            num_pages = len(pdf_reader.pages)
            logger.info(f"PDF has {num_pages} pages")

            # Extract text from each page (limit to first 20 pages for efficiency)
            max_pages = min(num_pages, 20)
            for page_num in range(max_pages):
                page = pdf_reader.pages[page_num]
                text = page.extract_text()

                if text:
                    extracted_text.append(text)

        # Combine all text
        full_text = '\n'.join(extracted_text)

        logger.info(f"Extracted {len(full_text)} characters from {max_pages} pages")

        return full_text

    except FileNotFoundError:
        logger.error(f"PDF file not found: {pdf_path}")
        return ""
    except Exception as e:
        logger.error(f"Error extracting text from PDF: {e}")
        return ""


def _extract_text_from_pdf_bytes(pdf_bytes: bytes) -> str:
    """
    Extract text from PDF bytes (for file uploads).

    Args:
        pdf_bytes: PDF file as bytes

    Returns:
        str: Extracted text
    """
    try:
        extracted_text = []

        pdf_file = io.BytesIO(pdf_bytes)
        pdf_reader = PyPDF2.PdfReader(pdf_file)

        num_pages = len(pdf_reader.pages)
        max_pages = min(num_pages, 20)  # Limit for efficiency

        for page_num in range(max_pages):
            page = pdf_reader.pages[page_num]
            text = page.extract_text()

            if text:
                extracted_text.append(text)

        full_text = '\n'.join(extracted_text)

        logger.info(f"Extracted {len(full_text)} characters from PDF bytes")

        return full_text

    except Exception as e:
        logger.error(f"Error extracting text from PDF bytes: {e}")
        return ""
